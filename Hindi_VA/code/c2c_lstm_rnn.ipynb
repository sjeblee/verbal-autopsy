{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the csv of the translated narratives to an xml tree\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "from lxml import etree\n",
    "import argparse\n",
    "import calendar\n",
    "import csv\n",
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import math \n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "data={}\n",
    "all_categories = []\n",
    "tree = etree.parse('../data/mds+rct/train_adult_cat.xml')\n",
    "for e in tree.iter(\"cghr_cat\"):\n",
    "        if e.text not in data:\n",
    "             data[e.text]=[]\n",
    "             all_categories.append(e.text)\n",
    "for e in tree.iter(\"narrative\",\"cghr_cat\"):\n",
    "    if e.tag == \"narrative\":\n",
    "        value= u''.join(e.text)\n",
    "#         print(value)\n",
    "        \n",
    "    if e.tag == 'cghr_cat':\n",
    "        data[e.text].append(value)\n",
    "\n",
    "\n",
    "# for k,v in data.iteritems():\n",
    "#     print (k)\n",
    "#     print ((u\"\\n\".join(v)))\n",
    "\n",
    "n_categories= len(all_categories)\n",
    "  \n",
    "            \n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "tensor([[   5.],\n",
      "        [  31.],\n",
      "        [  64.],\n",
      "        [  47.],\n",
      "        [  64.],\n",
      "        [  68.],\n",
      "        [   7.],\n",
      "        [  15.],\n",
      "        [  64.],\n",
      "        [  15.],\n",
      "        [   5.],\n",
      "        [  65.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  67.],\n",
      "        [  64.],\n",
      "        [  15.],\n",
      "        [ 101.],\n",
      "        [  15.],\n",
      "        [   5.],\n",
      "        [  32.],\n",
      "        [ 105.],\n",
      "        [   5.],\n",
      "        [  11.],\n",
      "        [  68.],\n",
      "        [  65.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  71.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [   9.],\n",
      "        [  41.],\n",
      "        [  12.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  11.],\n",
      "        [  68.],\n",
      "        [  43.],\n",
      "        [  64.],\n",
      "        [  32.],\n",
      "        [   5.],\n",
      "        [  67.],\n",
      "        [ 105.],\n",
      "        [  12.],\n",
      "        [  32.],\n",
      "        [  16.],\n",
      "        [  12.],\n",
      "        [   5.],\n",
      "        [  62.],\n",
      "        [ 105.],\n",
      "        [  32.],\n",
      "        [   5.],\n",
      "        [  35.],\n",
      "        [  15.],\n",
      "        [  32.],\n",
      "        [   5.],\n",
      "        [  35.],\n",
      "        [  15.],\n",
      "        [   5.],\n",
      "        [  59.],\n",
      "        [  68.],\n",
      "        [   5.],\n",
      "        [  50.],\n",
      "        [  50.],\n",
      "        [   5.],\n",
      "        [  35.],\n",
      "        [  15.],\n",
      "        [   5.],\n",
      "        [  71.],\n",
      "        [  65.],\n",
      "        [  61.],\n",
      "        [   5.],\n",
      "        [   5.],\n",
      "        [  32.],\n",
      "        [   5.],\n",
      "        [  30.],\n",
      "        [   4.],\n",
      "        [  65.],\n",
      "        [  32.],\n",
      "        [   5.],\n",
      "        [  31.],\n",
      "        [  65.],\n",
      "        [  32.],\n",
      "        [  74.],\n",
      "        [   5.],\n",
      "        [  64.],\n",
      "        [  67.],\n",
      "        [  74.],\n",
      "        [ 101.],\n",
      "        [  64.],\n",
      "        [   5.],\n",
      "        [   3.],\n",
      "        [  68.],\n",
      "        [  15.],\n",
      "        [  67.],\n",
      "        [   5.],\n",
      "        [  41.],\n",
      "        [   5.],\n",
      "        [  93.],\n",
      "        [  77.],\n",
      "        [   5.],\n",
      "        [  31.],\n",
      "        [  65.],\n",
      "        [  32.],\n",
      "        [   5.],\n",
      "        [   7.],\n",
      "        [ 105.],\n",
      "        [  12.],\n",
      "        [   5.],\n",
      "        [  60.],\n",
      "        [  67.],\n",
      "        [  68.],\n",
      "        [  15.],\n",
      "        [  65.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  12.],\n",
      "        [  93.],\n",
      "        [  15.],\n",
      "        [   5.],\n",
      "        [  60.],\n",
      "        [  68.],\n",
      "        [  40.],\n",
      "        [  15.],\n",
      "        [  12.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  31.],\n",
      "        [  65.],\n",
      "        [  41.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  63.],\n",
      "        [  18.],\n",
      "        [ 115.],\n",
      "        [  85.],\n",
      "        [  23.],\n",
      "        [ 118.],\n",
      "        [  86.],\n",
      "        [ 113.],\n",
      "        [  87.],\n",
      "        [  63.],\n",
      "        [   5.],\n",
      "        [  30.],\n",
      "        [  71.],\n",
      "        [  47.],\n",
      "        [   9.],\n",
      "        [  64.],\n",
      "        [  15.],\n",
      "        [  12.],\n",
      "        [   5.],\n",
      "        [  12.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  93.],\n",
      "        [ 101.],\n",
      "        [  74.],\n",
      "        [   5.],\n",
      "        [  40.],\n",
      "        [  41.],\n",
      "        [  15.],\n",
      "        [   5.],\n",
      "        [  34.],\n",
      "        [  15.],\n",
      "        [  32.],\n",
      "        [  64.],\n",
      "        [  68.],\n",
      "        [   5.],\n",
      "        [  65.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  31.],\n",
      "        [  65.],\n",
      "        [  41.],\n",
      "        [ 109.],\n",
      "        [   5.],\n",
      "        [  11.],\n",
      "        [  68.],\n",
      "        [  43.],\n",
      "        [  64.],\n",
      "        [  32.],\n",
      "        [   5.],\n",
      "        [  60.],\n",
      "        [   5.],\n",
      "        [  32.],\n",
      "        [  68.],\n",
      "        [   5.],\n",
      "        [   7.],\n",
      "        [ 105.],\n",
      "        [ 101.]])\n",
      "torch.Size([191, 1])\n"
     ]
    }
   ],
   "source": [
    "all_text = ''\n",
    "for v in data.itervalues():\n",
    "    all_text = all_text + u\"-\".join(v)\n",
    "\n",
    "vocab = set(all_text)\n",
    "n_letters = len(vocab)\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return list(vocab).index(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(narrative):\n",
    "    tensor = torch.zeros(len(narrative),1)\n",
    "    for li, letter in enumerate(narrative):\n",
    "        tensor[li][0] = letterToIndex(letter)\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('a'))\n",
    "narr = data['1'][0]\n",
    "print(lineToTensor(narr))\n",
    "print(lineToTensor(narr).size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder = nn.Embedding(input_size,20)\n",
    "        self.lstm = nn.LSTM(20,hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size,output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.long())\n",
    "        output,hidden = self.lstm(input,hidden)\n",
    "        output = self.linear(output[-1])\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "lstm = LSTM(n_letters, n_hidden, n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([191, 1])\n",
      "torch.Size([191, 1, 20])\n",
      "tensor([[-2.8784, -2.9683, -2.6928, -2.8717, -2.9444, -2.9414, -2.8469,\n",
      "         -2.9607, -2.9037, -2.8476, -2.8702, -2.9758, -2.9996, -2.8396,\n",
      "         -2.8535, -2.9868, -2.8491, -2.8452]])\n",
      "torch.Size([1, 18])\n"
     ]
    }
   ],
   "source": [
    "input = lineToTensor(narr)\n",
    "print(input.size())\n",
    "hidden = torch.zeros(1,1,n_hidden)\n",
    "\n",
    "output, next_hidden = lstm(input,None)\n",
    "print(output)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('19', 2)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = 1 tensor([ 5]) / line =   को ________ दाी के पास घर मे ही \"baby\" को \"delivery\" हुी बचची बिलकुल सवसथ लग रही थी आधे घंटे बाद ही उसने \"Bottle\" से दूध पीना शुरू कर दिया था और उसी दिन शाम को मां का दूध भी पीना शुरू कर दिया कोी \"problem\" नही थी चौथे दिन सुबह उसने दूध पिया उसके बाद उसे थोडा सा बुखार लग रहा था घर के पास ही एक डाुक्टर को दिखाया तो उसने बताया की उसे थंड लग गी है दवाी भी दे दी मगर चर पांच घंटे बाद ही उसकी अचानक सांस बंद हो गी और \"death\" हो गी\n",
      "category = 19 tensor([ 2]) / line =  बच्चा अस्पताल मे ही जन्म था और जन्म के समय ही कम पैदा हुा था  ही थोदी देर मे खतम हो गया राय मशविरा कर रहे थे कि कया किया जाये कहां ले जाये, उससे पहले वो खतम हो चुका था\n",
      "category = 12 tensor([ 7]) / line =  उत्तरदाता के अनुसार मृतक कुसुम खातुन की मृत्यु हरदय गति के रुक जाने के कारण हुा कुसुम खातुन को कुछ दिन से कमजोरी था तथा कभी कभी चक्कर भी आता था तथा इसके साथ - साथ कभी कभी कुछ काम करते गिर भी जाती थी उसने इसका इलाज किसी प्रशिकषित डाक्टर से न कराकर गांव के ही ओसा से जाड-फूल करवाने लगी इससे उनकी बीमारी दिन-प्रतिदिन बढते ही गी दिनांक  को सुबह में ब्रश कर रही थी तथा अचानक वह गिर पडी उसे देखकर कुछ लोग उसे अस्पताल ले जाने लगे तब रास्ता में ही उसकी मृत्यु हो गी थी\n",
      "category = 3 tensor([ 0]) / line =  उत्तरदाता गजानंद मृतका गिननी देवी के अनुसार उनकी दादी की उमर करीब  वरष थी उनको काफी कम थी अदिक आयु कम मे  दिन पहले मृत्यु के उनको उलटी व दस्त भी हो गये जिसके कारण शरीर मे काफी कम आ गयी इसी दौरान उनकी दादी का निधन हो गया\n",
      "category = 12 tensor([ 7]) / line =  उत्तरदाता के अनुसार मृतक कुसुम खातुन की मृत्यु हरदय गति के रुक जाने के कारण हुा कुसुम खातुन को कुछ दिन से कमजोरी था तथा कभी कभी चक्कर भी आता था तथा इसके साथ - साथ कभी कभी कुछ काम करते गिर भी जाती थी उसने इसका इलाज किसी प्रशिकषित डाक्टर से न कराकर गांव के ही ओसा से जाड-फूल करवाने लगी इससे उनकी बीमारी दिन-प्रतिदिन बढते ही गी दिनांक  को सुबह में ब्रश कर रही थी तथा अचानक वह गिर पडी उसे देखकर कुछ लोग उसे अस्पताल ले जाने लगे तब रास्ता में ही उसकी मृत्यु हो गी थी\n",
      "category = 14 tensor([ 16]) / line =  उत्तरदाता ने बताया की मृतक का बचचे की मृत्यु किसी दुरघटना से नहीं हुी उसको जन्म ठीक - ठाक अस्पताल में पुरे  महीने में हुा था उसके पहले किसी तरह की कोी बीमारी नहीं थी बचचे ने स्तनपान भी ठीक - ठाक किया उसको किसी अनय प्रकार की कोी बीमारी नहीं थी परन्तु उनके शरीर पर पीठ पर एक लाल रंग का फोडा था जिसके कारण बच्चा काफी परेशान रहता था उसको _______ हुा था उसका इलाज पहले तो किसी नजदीकी अस्पताल में दिखाया गया उसके बाद वहां पर इसको की दिन तक इलाज चलता रहा परन्तु की दिन के बाद भी उसको आराम नहीं हुा वही पर डाक्टर ने उसको मृत घोसित कर दिया\n",
      "category = 8 tensor([ 11]) / line =  उत्तरदाता ने बताया की उसकी पतनी को फेफडो का कैंसर था जिसके कारण अस्पताल में भरती कराया गया था और काफी समय से उसका इलाज चल रहा था वह बहुत काम खाती-पीती थी और इलाज के बावजूद उसकी हालत खराब होती जा रही थी उसे छाती में दरद रहता था खांसी आती थी कभी -  खांसी में खून भी आता था उसे सब से अधिक तकलीफ साणस लेने में होती थी और इसी कारण उसकी मृत्यु हो गयी\n",
      "category = 16 tensor([ 13]) / line =  उत्तरदाता के अनुसार मृतक ने एक दिन घर पर किसी वजह से पकांसी लगाकर आतमहतया कर लिया\n",
      "category = 10 tensor([ 9]) / line =  मृतक की आयु  वरष की थी लगभग दो वरष से लकवा से पी थी बांयी तरफ शरीर लकवा से प्रभावित था इसी अवसथा मे घर पर मृत्यु हो गयी\n",
      "category = 8 tensor([ 11]) / line =  उत्तरदाता के अनुसार मृतक को पैर में कैंसर था जिसका इलाज वाराणसी से चल रहा था लगभग  वरष बीत जाने के बाद भी उसको कोी सुधार नहीं हो रहा था और दवा घर पर चलने लगा एक दिन अचानक वो बेहोश होकर गिर पडा और देखने के बाद पता चला की उसकी मृत्यु हो गी\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(data[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = lineToTensor(line)\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category,category_tensor, '/ line =', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # If you set this too high, it might explode. If too low, it might not learn\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "#     hidden = rnn.initHidden()\n",
    "\n",
    "    lstm.zero_grad()\n",
    "    output, hidden = lstm(line_tensor,None)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "def save():\n",
    "    save_filename = \"./model.pt\"\n",
    "    torch.save(lstm, save_filename)\n",
    "    print('Saved as %s' % save_filename)\n",
    "    \n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "n_iters = 100000\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    output, loss = train(category_tensor, line_tensor)\n",
    "    current_loss += loss\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    if iter % print_every == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0\n",
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct cat: 11 , predicted cat: 3\n",
      "correct cat: 10 , predicted cat: 12\n",
      "correct cat: 12 , predicted cat: 2\n",
      "correct cat: 12 , predicted cat: 2\n",
      "correct cat: 15 , predicted cat: 8\n",
      "correct cat: 15 , predicted cat: 17\n",
      "correct cat: 15 , predicted cat: 19\n",
      "correct cat: 15 , predicted cat: 19\n",
      "correct cat: 15 , predicted cat: 9\n",
      "correct cat: 14 , predicted cat: 14\n",
      "correct cat: 14 , predicted cat: 13\n",
      "correct cat: 14 , predicted cat: 2\n",
      "correct cat: 14 , predicted cat: 3\n",
      "correct cat: 17 , predicted cat: 9\n",
      "correct cat: 17 , predicted cat: 9\n",
      "correct cat: 17 , predicted cat: 14\n",
      "correct cat: 17 , predicted cat: 9\n",
      "correct cat: 17 , predicted cat: 18\n",
      "correct cat: 17 , predicted cat: 4\n",
      "correct cat: 16 , predicted cat: 3\n",
      "correct cat: 16 , predicted cat: 18\n",
      "correct cat: 16 , predicted cat: 15\n",
      "correct cat: 16 , predicted cat: 8\n",
      "correct cat: 19 , predicted cat: 17\n",
      "correct cat: 19 , predicted cat: 10\n",
      "correct cat: 19 , predicted cat: 3\n",
      "correct cat: 19 , predicted cat: 19\n",
      "correct cat: 18 , predicted cat: 2\n",
      "correct cat: 18 , predicted cat: 7\n",
      "correct cat: 18 , predicted cat: 14\n",
      "correct cat: 18 , predicted cat: 12\n",
      "correct cat: 18 , predicted cat: 2\n",
      "correct cat: 18 , predicted cat: 1\n",
      "correct cat: 18 , predicted cat: 1\n",
      "correct cat: 18 , predicted cat: 14\n",
      "correct cat: 18 , predicted cat: 19\n",
      "correct cat: 3 , predicted cat: 9\n",
      "correct cat: 2 , predicted cat: 2\n",
      "correct cat: 2 , predicted cat: 15\n",
      "correct cat: 4 , predicted cat: 12\n",
      "correct cat: 4 , predicted cat: 8\n",
      "correct cat: 4 , predicted cat: 2\n",
      "correct cat: 4 , predicted cat: 2\n",
      "correct cat: 4 , predicted cat: 18\n",
      "correct cat: 4 , predicted cat: 19\n",
      "correct cat: 7 , predicted cat: 8\n",
      "correct cat: 7 , predicted cat: 12\n",
      "correct cat: 7 , predicted cat: 1\n",
      "correct cat: 7 , predicted cat: 2\n",
      "correct cat: 7 , predicted cat: 9\n",
      "correct cat: 7 , predicted cat: 16\n",
      "correct cat: 9 , predicted cat: 2\n",
      "correct cat: 9 , predicted cat: 12\n",
      "correct cat: 9 , predicted cat: 8\n",
      "correct cat: 9 , predicted cat: 18\n",
      "correct cat: 8 , predicted cat: 8\n",
      "correct cat: 8 , predicted cat: 19\n",
      "correct cat: 8 , predicted cat: 8\n",
      "correct cat: 8 , predicted cat: 1\n",
      "total test: 59\n",
      "total correct: 5\n",
      "prediction: 8.474576\n"
     ]
    }
   ],
   "source": [
    "evaluator = torch.load(\"./model.pt\")\n",
    "# -*- coding: UTF-8 -*-\n",
    "test_data={}\n",
    "\n",
    "tree = etree.parse('../data/mds+rct/dev_adult_cat.xml')\n",
    "for e in tree.iter(\"cghr_cat\"):\n",
    "        if e.text not in test_data:\n",
    "             test_data[e.text]=[]\n",
    "for e in tree.iter(\"narrative\",\"cghr_cat\"):\n",
    "    if e.tag == \"narrative\":\n",
    "        value= u''.join(e.text)\n",
    "#         print(value)\n",
    "        \n",
    "    if e.tag == 'cghr_cat':\n",
    "        test_data[e.text].append(value)\n",
    "\n",
    "total_test = 0\n",
    "total_correct = 0\n",
    "for k,v in test_data.items():\n",
    "    cat = k\n",
    "    for line in v:\n",
    "        narr = line\n",
    "        narr_tensor = lineToTensor(line)\n",
    "        output,hidden = evaluator(narr_tensor,None)\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        print(\"correct cat: %s , predicted cat: %s\"%(cat,guess))\n",
    "        total_test +=1\n",
    "        if cat == guess:\n",
    "            total_correct +=1\n",
    "\n",
    "print(\"total test: %d\"%(total_test))\n",
    "print(\"total correct: %d\"%(total_correct))\n",
    "print(\"prediction: %f\"%((total_correct/total_test)*100))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
