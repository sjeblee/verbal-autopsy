{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*-coding:UTF-8-*-\n",
    "import string\n",
    "\n",
    "#list of consonants \n",
    "consonants = [\"k\",\"kh\",\"g\",\"gh\",\"ch\",\"Ch\",\"j\",\"jh\",\"T\",\"Th\",\"D\",\"Dh\",\"N\",\"t\",\"th\",\"d\",\"dh\",\"n\",\"p\",\"ph\",\"b\",\"bh\",\"m\",\"y\",\\\n",
    "                    \"r\",\"l\",\"v\",\"w\",\"sh\",\"Sh\",\"s\",\"h\"]\n",
    "\n",
    "#list of vowels \n",
    "vowels = [\"a\",\"A\",\"i\",\"I\",\"u\",\"U\",\"E\",\"ai\",\"O\",\"au\",\"RRi\",\"RRI\",\"LLi\",\"LLI\",\"M\",\"H\",\"OM\"]\n",
    "\n",
    "#list of consonant_cluster\n",
    "consonants_cluster = [\"xa\",\"tra\",\"GYa\",\"shra\"]\n",
    "\n",
    "#list of consonants with nuqta \n",
    "consonants_nuqta = [\"qa\",\"Kha\",\"Ga\",\"za\",\"fa\",\"Ra\",\"Rha\"]\n",
    "\n",
    "#list of half_forms \n",
    "half_forms = [\"tta\" ,\"lkA\",\"svA\",\"sthya\",\"spa\",\"chcha\",\"kta\",\"nhEM\",\"nhOM\",\"sya\",\"mba\",\"ndhI\",\"kTa\",\"bla\",\"bbE\",\"sthi\",\\\n",
    "                    \"tyu\",\"chchA\",\"ntu\",\"lga\",\"shki\",\"stE\",\"sta\",\"jyA\",\"ddha\",\"vya\",\"kka\",\"stA\",\"bra\",\"pra\",\"nma\",\"rva\"]\n",
    "#list of punctuations \n",
    "punctuations = [\".\",\"\\n\"]\n",
    "\n",
    "\n",
    "#dictionary mapping consonants to the hindi characters \n",
    "consonant_mapping = {\"k\":'क',\"kh\":'ख',\"g\":'ग',\"gh\":'घ',\"ch\":'च',\"Ch\":'छ',\"j\":'ज',\"jh\":'झ',\"T\":'ट',\"Th\":'ठ',\"D\":'ड',\"Dh\":'ढ',\"N\":'ण',\\\n",
    "            \"t\":'त',\"th\":'थ',\"d\":'द',\"dh\":'ध',\"n\":'न',\"p\":'प',\"ph\":'फ',\"b\":'ब',\"bh\":'भ',\"m\":'म',\"y\":'य',\"r\":'र',\"l\":'ल',\\\n",
    "                \"v\":'व',\"w\":'व',\"sh\":'श',\"Sh\":'ष',\"s\":'स',\"h\":'ह'}\n",
    "\n",
    "#dictionary mapping vowels to the hindi characters \n",
    "vowels_mapping = {\"a\":'अ',\"A\":'आ',\"i\":'इ',\"I\":'ई',\"u\":'उ',\"U\":'ऊ',\"E\":'ए',\"ai\":'ऐ',\"O\":'ओ',\"au\":'औ',\"RRi\":'ऋ',\\\n",
    "                    \"RRI\":'ॠ',\"LLi\":'ऌ',\"LLI\":'ॡ',\"M\":'अं',\"H\":'अः',\"OM\":'ॐ'}\n",
    "\n",
    "\n",
    "\n",
    "#dictionary mapping consonant clusters to the hindi characters \n",
    "cc_mapping={\"xa\":'क्ष',\"tra\":'त्र',\"GYa\":'ज्ञ',\"shra\":'श्र'}\n",
    "\n",
    "#dictionary mapping half forms to the hindi characters \n",
    "halfforms_mapping={\"tta\":'त्त' ,\"lkA\":'ल्का ',\"svA\":'स्वा',\"sthya\":'स्थ्य',\"spa\":'स्प',\"chcha\":'च्च',\"kta\":'क्त',\"nhEM\":'न्हें',\"nhOM\":'न्हों',\\\n",
    "                        \"sya\":'स्य',\"mba\":'म्ब',\"ndhI\":'न्धी',\"kTa\":'क्ट',\"bla\":'ब्ल',\"bbE\":'ब्बे',\"sthi\":'स्थि',\"tyu\":'त्यु',\"chchA\":'च्चा',\\\n",
    "                    \"ntu\":'न्तु',\"lga\":'ल्ग',\"shki\":'श्कि',\"stE\":'स्ते',\"sta\":'स्त',\"jyA\":'ज्या',\"ddha\":'द्ध',\"vya\":'व्य',\"kka\":'क्क',\"stA\":'स्ता',\\\n",
    "                    \"bra\":'ब्र',\"pra\":'प्र',\"nma\":'न्म',\"rva\":'र्व'}\n",
    "\n",
    "#dictionary mapping consonant with nuqtas to the hindi characters \n",
    "conso_nuqta_mapping ={\"qa\":'क़',\"Kha\":'ख़',\"Ga\":'ग़',\"za\":'ज़',\"fa\":'फ़',\"Ra\":'ड़',\"Rha\":'ढ़'}\n",
    "\n",
    "hindi_consonant=['क','ख','ग','घ','च','छ','ज','झ','ट','ठ','ड','ढ','ण',\\\n",
    "            'त','थ','द','ध','न','प','फ','ब','भ','म','य','र','ल',\\\n",
    "                'व','श','ष','स','ह']\n",
    "#mapping of vowels when they are used with consonants \n",
    "vowels_translation = {'अ':'','आ':'ा','इ':'ि','ई':'ी','उ':'ु','ऊ':'ू','ए':'े','ऐ':'ै','ओ':'ो','औ':'ौ','ऋ':'ृ',\\\n",
    "                    'ॠ':'ॄ','ऌ':'ॢ','ॡ':'ॣ','अं':'ं','अः':'ः','ॐ':''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove punctuation from the text\n",
    "def remove_punctuation(words):\n",
    "\n",
    "    words_processed=[]\n",
    "    for word in words:\n",
    "        no_punct = \"\"\n",
    "        for char in word:\n",
    "            if char not in punctuations:\n",
    "                no_punct = no_punct + char\n",
    "        words_processed.append(no_punct)\n",
    "    return words_processed\n",
    "\n",
    "#returns true if given char is in the specified group\n",
    "def check(group,char):\n",
    "    if char in group:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#returns hindi character for specified letter in english \n",
    "def find_mapping(mapping_dict,letter):\n",
    "    return mapping_dict[letter]\n",
    "\n",
    "\n",
    "#returns closest hindi mapping along with type of the hindi character \n",
    "def get_letters(word):\n",
    "\n",
    "    type = ''\n",
    "    if check(vowels,word):\n",
    "        hindi = find_mapping(vowels_mapping,word)\n",
    "        type = 'vowel'\n",
    "        return True,hindi,type\n",
    "\n",
    "    elif check(consonants,word):\n",
    "        #print (\"Consonants:  \"+word)\n",
    "        #print find_mapping(consonant_mapping, word)\n",
    "        hindi = find_mapping(consonant_mapping,word)\n",
    "        type = 'consonant'\n",
    "        return True,hindi,type\n",
    "    elif check(consonants_cluster,word):\n",
    "        hindi = find_mapping(cc_mapping,word)\n",
    "        return True,hindi,type\n",
    "    elif check(consonants_nuqta,word):\n",
    "        hindi = find_mapping(conso_nuqta_mapping,word)\n",
    "        return True,hindi,type\n",
    "    elif check(half_forms,word):\n",
    "        hindi = find_mapping(halfforms_mapping,word)\n",
    "        return True,hindi,type\n",
    "    elif word in string.punctuation and word !=\"\\\"\":\n",
    "        hindi = word\n",
    "        return True,hindi,type\n",
    "    else:\n",
    "        hindi=\"\"\n",
    "        return False,hindi,type\n",
    "\n",
    "\n",
    "def process(word,is_english):\n",
    "    #results={}\n",
    "\n",
    "\n",
    "    current_index = 0\n",
    "    last_index = len(word)\n",
    "    result =''\n",
    "    meaning = ''\n",
    "    previous_previous_type=''\n",
    "    previous_type = ''\n",
    "    current_type=''\n",
    "    previous_char = ''\n",
    "    previous_previous_char=''\n",
    "    \n",
    "    if is_english:\n",
    "        result = word\n",
    "        meaning = word\n",
    "        return result,meaning\n",
    "    else:\n",
    "        \n",
    "        while(current_index != len(word) and last_index>0):\n",
    "\n",
    "            is_found,hindi,current_type = get_letters(word[current_index:last_index])\n",
    "            if(is_found and hindi != \"\"):\n",
    "                result = result + word[current_index:last_index]\n",
    "\n",
    "                if current_type == 'vowel':\n",
    "                    if previous_type == 'consonant':\n",
    "                        meaning = meaning+vowels_translation[hindi]\n",
    "                        #previous_type = ''\n",
    "                    elif previous_type == 'vowel':\n",
    "                        meaning = meaning+vowels_translation[hindi]\n",
    "                        #previous_type = ''\n",
    "                        \n",
    "                    else:\n",
    "                        meaning = meaning+hindi\n",
    "                        #previous_type =''\n",
    "                else:\n",
    "                    previous_type = current_type\n",
    "                    meaning = meaning+hindi\n",
    "\n",
    "\n",
    "                current_index = last_index\n",
    "                last_index = len(word)\n",
    "            else:\n",
    "                last_index = last_index-1\n",
    "        return result,meaning\n",
    "\n",
    "\n",
    "#if hindi word is made up of consonants followed by vowels, then it replaces the consonant and vowel\n",
    "#with appropriate mapping \n",
    "def process_hindi_words(word):\n",
    "    \n",
    "    i = 0\n",
    "    j= 1\n",
    "    while(j <= len(word)):\n",
    "        if(word[i] in hindi_consonant and word[j] in vowels_translation.keys()):\n",
    "            char = word[i]+vowels_translation[word[j]]\n",
    "            print char\n",
    "            i = i + 2\n",
    "            j = j + 2\n",
    "        else:\n",
    "            i = i+2\n",
    "            j=j+2\n",
    "\n",
    "            \n",
    "#read from hindi narratives and write the translation into the results file             \n",
    "def process_data(entry):\n",
    "    words = remove_punctuation(entry.split(\" \"))\n",
    "\n",
    "    result = ''\n",
    "    is_english = False\n",
    "    for word in words:\n",
    "\n",
    "        if len(word)>0:\n",
    "            if word[0]==\"\\\"\" and word[len(word)-1]==\"\\\"\":\n",
    "                is_english = True\n",
    "                item,trans = process(word,is_english)\n",
    "                is_english = False  \n",
    "            elif word[0]==\"\\\"\":\n",
    "                is_english = True\n",
    "                item,trans = process(word,is_english)\n",
    "            elif word[len(word)-1]==\"\\\"\":\n",
    "                item,trans = process(word,is_english)\n",
    "                is_english = False\n",
    "            else:\n",
    "                item,trans = process(word,is_english)\n",
    "        #print item+\":\"+trans\n",
    "            result = result+\" \"+trans\n",
    "    return (result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Convert the csv of the translated narratives to an xml tree\n",
    "\n",
    "import sys\n",
    "from lxml import etree\n",
    "import argparse\n",
    "import calendar\n",
    "import csv\n",
    "import re\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325434\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "total_char=0\n",
    "tree = etree.parse('../../../../data/mds+rct/all_adult_cat_second.xml')\n",
    "for e in tree.iter():\n",
    "    if e.tag == 'narrative':\n",
    "        data.append(e.text)\n",
    "\n",
    "for n in data:\n",
    "        total_char += len(n)\n",
    "print(total_char)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data={}\n",
    "tree = etree.parse('../data/mds+rct/all_adult_cat.xml')\n",
    "for e in tree.iter():\n",
    "    if e.tag == 'cghr_cat':\n",
    "        if e.text in data:\n",
    "                   data[e.text] += 1\n",
    "        else:\n",
    "            data[e.text]=1\n",
    "x = []\n",
    "y=[]\n",
    "for k,v in data.items() :\n",
    "    x.append(int(k))\n",
    "    y.append(v)\n",
    "y_pos = np.arange(len(x))\n",
    "plt.bar(y_pos,y,align = 'center',alpha=0.5)\n",
    "plt.xticks(y_pos, x)\n",
    "plt.show()\n",
    "                   \n",
    "                   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#XML Root Information\n",
    "adult_root = etree.Element(\"root\")\n",
    "adult_tag = \"Adult_Anonymous\"\n",
    "id_tag = \"MG_ID\"\n",
    "narr_tag_hindi = \"narrative\"\n",
    "narr_tag_eng= \"original_narr\"\n",
    "code_tag = \"Final_code\"\n",
    "p1_keywords_tag = \"keywords_p1\"\n",
    "p1_icd_tag = \"icd_p1\"\n",
    "p2_keywords_tag = \"keywords_p2\"\n",
    "p2_icd_tag = \"icd_p2\"\n",
    "\n",
    "#CSV Parser Codes\n",
    "id_name = 'id'\n",
    "narrative = 'transcribed_mds_narrative'\n",
    "final_code = 'final_code'\n",
    "p1_keywords = 'p1_keywords'\n",
    "p1_icd = 'p1_icd'\n",
    "p2_keywords = 'p2_keywords'\n",
    "p2_icd = 'p2_icd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = etree.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_file = '../data/mds_narrative_hindi.xml'\n",
    "with open (\"../data/mds_narrative_hindi.csv\",'rb') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            root = adult_root\n",
    "            tag = adult_tag\n",
    "            child = etree.SubElement(root,tag)\n",
    "            id_node = etree.SubElement(child,id_tag)\n",
    "            id_node.text = row[id_name]\n",
    "\n",
    "            if row[narrative] != 'NULL':\n",
    "                narr_hindi_node = etree.SubElement(child,narr_tag_hindi)\n",
    "                hindi_version = process_data(row[narrative])\n",
    "                hindi_version = hindi_version.decode('utf-8','ignore')\n",
    "                narr_hindi_node.text = hindi_version\n",
    "                narr_english_node = etree.SubElement(child,narr_tag_eng)\n",
    "                narr_english_node.text = row[narrative]\n",
    "                \n",
    "                \n",
    "\n",
    "            p1key_node = etree.SubElement(child,p1_keywords_tag)\n",
    "            p1key_node.text = row[p1_keywords]\n",
    "\n",
    "            p1icd_node = etree.SubElement(child,p1_icd_tag)\n",
    "            p1icd_node.text = row[p1_icd]\n",
    "\n",
    "            p2key_node = etree.SubElement(child,p2_keywords_tag)\n",
    "            p2key_node.text = row[p2_keywords]\n",
    "\n",
    "            p2icd_node = etree.SubElement(child,p2_icd_tag)\n",
    "            p2icd_node.text = row[p2_icd]\n",
    "\n",
    "            icd_node = etree.SubElement(child,code_tag)\n",
    "            icd_node.text = row[final_code]\n",
    "            \n",
    "        except ValueError:\n",
    "            print row\n",
    "        #print(etree.tostring(root, pretty_print=True))\n",
    "        #break\n",
    "\n",
    "etree.ElementTree(adult_root).write(output_file)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
